import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import (confusion_matrix, classification_report, 
                             accuracy_score, precision_score, recall_score, f1_score)
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

print("="*80)
print("PRODUCT REVIEW SENTIMENT ANALYSIS - NLP PROJECT")
print("="*80)
print("\n[STEP 1] GENERATING SYNTHETIC PRODUCT REVIEW DATASET...")
print("-" * 80)

np.random.seed(42)

# Positive review templates
positive_reviews = [
    "This product is absolutely amazing! I love it so much.",
    "Excellent quality and fast shipping. Highly recommend!",
    "Best purchase I've made this year. Five stars!",
    "Outstanding product! Exceeded all my expectations.",
    "Great value for money. Very satisfied with this purchase.",
    "Perfect! Exactly what I was looking for.",
    "The quality is superb. I'm very happy with this item.",
    "Fantastic product! Works perfectly as described.",
    "Love it! Will definitely buy again.",
    "Amazing quality and excellent customer service.",
    "This is the best product I've ever used. Incredible!",
    "Very impressed with the build quality. Highly recommended.",
    "Awesome product! Does exactly what it promises.",
    "Exceptional value! I couldn't be happier.",
    "Perfect fit and great quality. Love it!",
    "Brilliant product! Solves all my problems.",
    "Top-notch quality. Worth every penny.",
    "Wonderful product! Very pleased with my purchase.",
    "Great design and functionality. Five stars!",
    "Impressive product! Exceeded my expectations completely.",
    "The product arrived quickly and works great.",
    "Superb quality and excellent performance.",
    "I'm thrilled with this purchase. Highly recommended!",
    "Outstanding value for the price. Love it!",
    "This product is a game-changer. Absolutely love it!",
    "Excellent craftsmanship and attention to detail.",
    "Best product in its category. Five stars!",
    "Very happy with the quality and performance.",
    "Amazing! This product is worth every dollar.",
    "Perfect product! No complaints whatsoever.",
    "High quality and works beautifully. Recommend it!",
    "Love everything about this product. Brilliant!",
    "Fantastic! Better than I expected.",
    "Great product at an affordable price. Happy customer!",
    "Superb! This is exactly what I needed.",
]

# Negative review templates
negative_reviews = [
    "Terrible product. Complete waste of money.",
    "Very disappointed. It broke after one day.",
    "Poor quality. Would not recommend to anyone.",
    "Awful! Nothing like the description.",
    "The worst purchase I've ever made. Avoid this!",
    "Cheap materials and poor construction. Very unhappy.",
    "Don't waste your money on this junk.",
    "Horrible experience. Product arrived damaged.",
    "Very poor quality. Not worth the price.",
    "Disappointing. Does not work as advertised.",
    "Terrible customer service and defective product.",
    "This product is garbage. Total rip-off.",
    "Waste of money. Broke immediately after use.",
    "Poor quality control. Received a defective item.",
    "Not as described. Very misleading advertising.",
    "Awful product. Save your money and buy something else.",
    "Cheaply made and doesn't work properly.",
    "Very dissatisfied. Product is useless.",
    "Terrible design and poor functionality.",
    "Don't buy this! Completely disappointed.",
    "Bad quality and overpriced. Not recommended.",
    "The product stopped working after a week.",
    "Poor performance and terrible build quality.",
    "Waste of time and money. Very frustrated.",
    "Horrible! Nothing works as it should.",
    "Cheap knockoff. Not worth purchasing.",
    "Very poor experience. Product is defective.",
    "Disappointed with the quality. Would return if I could.",
    "Terrible! Fell apart within days.",
    "Not functional. Complete waste of money.",
    "Bad investment. Regret buying this product.",
    "Poor quality materials. Breaks easily.",
    "Awful experience from start to finish.",
    "Defective product. Customer service was no help.",
    "Worst product ever. Stay away!",
]

# Generate dataset with variations
reviews = []
labels = []

# Generate 100 positive reviews with variations
for i in range(100):
    base_review = np.random.choice(positive_reviews)
    # Add some variation
    variations = [
        base_review,
        base_review + " Would buy again!",
        base_review + " Highly satisfied.",
        base_review + " Perfect for my needs.",
        "Wonderful! " + base_review,
        "Great experience. " + base_review,
    ]
    reviews.append(np.random.choice(variations))
    labels.append("Positive")

# Generate 100 negative reviews with variations
for i in range(100):
    base_review = np.random.choice(negative_reviews)
    # Add some variation
    variations = [
        base_review,
        base_review + " Very frustrated.",
        base_review + " Do not recommend.",
        base_review + " Save your money.",
        "Disappointing. " + base_review,
        "Terrible experience. " + base_review,
    ]
    reviews.append(np.random.choice(variations))
    labels.append("Negative")

# Create DataFrame
df = pd.DataFrame({
    'Review': reviews,
    'Sentiment': labels
})

# Shuffle the dataset
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

print(f"‚úì Generated {len(df)} product reviews")
print(f"\nDataset Preview:")
print(df.head(10))

print(f"\nClass Distribution:")
print(df['Sentiment'].value_counts())
print(f"\nPercentage Distribution:")
print(df['Sentiment'].value_counts(normalize=True) * 100)

# Save raw dataset
df.to_csv('/mnt/user-data/outputs/product_reviews_raw.csv', index=False)
print(f"\n‚úì Saved: product_reviews_raw.csv")
print("\n[STEP 2] TEXT PREPROCESSING...")
print("-" * 80)

# Common English stopwords (custom list)
stop_words = {
    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", 
    "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 
    'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 
    'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 
    'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 
    'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 
    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 
    'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 
    'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 
    'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 
    'there', 'when', 'where', 'why', 'how', 'all', 'both', 'each', 'few', 'more', 'most', 
    'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 
    'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 
    'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', 
    "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 
    'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 
    'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 
    'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"
}

def preprocess_text(text):
    """
    Comprehensive text preprocessing function
    - Converts to lowercase
    - Removes URLs, mentions, hashtags
    - Removes punctuation and special characters
    - Removes stopwords
    - Removes extra whitespace
    """
    # Convert to lowercase
    text = text.lower()
    
    # Remove URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    
    # Remove mentions and hashtags
    text = re.sub(r'@\w+|#\w+', '', text)
    
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Remove numbers
    text = re.sub(r'\d+', '', text)
    
    # Remove stopwords
    text = ' '.join([word for word in text.split() if word not in stop_words])
    
    # Remove extra whitespace
    text = ' '.join(text.split())
    
    return text

# Apply preprocessing
print("Preprocessing reviews...")
df['Review_Cleaned'] = df['Review'].apply(preprocess_text)

print("‚úì Text preprocessing completed")
print(f"\nExample of preprocessing:")
print(f"\nOriginal: {df['Review'].iloc[0]}")
print(f"Cleaned:  {df['Review_Cleaned'].iloc[0]}")

# Check text statistics
df['Word_Count'] = df['Review_Cleaned'].apply(lambda x: len(x.split()))
df['Char_Count'] = df['Review_Cleaned'].apply(lambda x: len(x))

print(f"\nText Statistics After Preprocessing:")
print(f"  Average words per review: {df['Word_Count'].mean():.2f}")
print(f"  Average characters per review: {df['Char_Count'].mean():.2f}")
print(f"  Min words: {df['Word_Count'].min()}")
print(f"  Max words: {df['Word_Count'].max()}")

print("\n[STEP 3] TF-IDF VECTORIZATION...")
print("-" * 80)

# Initialize TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(
    max_features=500,  
    min_df=2,          
    max_df=0.8,        
    ngram_range=(1, 2) 
)

# Fit and transform the text data
X = tfidf_vectorizer.fit_transform(df['Review_Cleaned'])
y = df['Sentiment'].map({'Positive': 1, 'Negative': 0})

print(f"‚úì TF-IDF vectorization completed")
print(f"  Feature matrix shape: {X.shape}")
print(f"  Number of features (words): {X.shape[1]}")
print(f"  Sparse matrix density: {(X.nnz / (X.shape[0] * X.shape[1]) * 100):.2f}%")

# Display top features
feature_names = tfidf_vectorizer.get_feature_names_out()
print(f"\nTop 20 features (words/bigrams):")
print(feature_names[:20])

print("\n[STEP 4] SPLITTING DATA INTO TRAIN AND TEST SETS...")
print("-" * 80)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"‚úì Data split completed")
print(f"  Training set size: {X_train.shape[0]} samples ({(X_train.shape[0]/len(df)*100):.1f}%)")
print(f"  Test set size: {X_test.shape[0]} samples ({(X_test.shape[0]/len(df)*100):.1f}%)")
print(f"  Positive samples in train: {y_train.sum()}")
print(f"  Negative samples in train: {len(y_train) - y_train.sum()}")

print("\n[STEP 5A] TRAINING LOGISTIC REGRESSION MODEL...")
print("-" * 80)

# Train Logistic Regression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train, y_train)

# Make predictions
y_pred_lr = lr_model.predict(X_test)

# Calculate metrics
lr_accuracy = accuracy_score(y_test, y_pred_lr)
lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)

print(f"‚úì Logistic Regression training completed")
print(f"\nLOGISTIC REGRESSION PERFORMANCE:")
print(f"  Accuracy:  {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)")
print(f"  Precision: {lr_precision:.4f}")
print(f"  Recall:    {lr_recall:.4f}")
print(f"  F1-Score:  {lr_f1:.4f}")

print("\n[STEP 5B] TRAINING NAIVE BAYES MODEL...")
print("-" * 80)

# Train Naive Bayes
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)

# Make predictions
y_pred_nb = nb_model.predict(X_test)

# Calculate metrics
nb_accuracy = accuracy_score(y_test, y_pred_nb)
nb_precision = precision_score(y_test, y_pred_nb)
nb_recall = recall_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb)

print(f"‚úì Naive Bayes training completed")
print(f"\nNAIVE BAYES PERFORMANCE:")
print(f"  Accuracy:  {nb_accuracy:.4f} ({nb_accuracy*100:.2f}%)")
print(f"  Precision: {nb_precision:.4f}")
print(f"  Recall:    {nb_recall:.4f}")
print(f"  F1-Score:  {nb_f1:.4f}")

print("\n[STEP 6] MODEL COMPARISON...")
print("-" * 80)

comparison_df = pd.DataFrame({
    'Model': ['Logistic Regression', 'Naive Bayes'],
    'Accuracy': [lr_accuracy, nb_accuracy],
    'Precision': [lr_precision, nb_precision],
    'Recall': [lr_recall, nb_recall],
    'F1-Score': [lr_f1, nb_f1]
})

print("\nModel Performance Comparison:")
print(comparison_df.to_string(index=False))

# Select best model
best_model_name = 'Logistic Regression' if lr_accuracy >= nb_accuracy else 'Naive Bayes'
best_model = lr_model if lr_accuracy >= nb_accuracy else nb_model
best_predictions = y_pred_lr if lr_accuracy >= nb_accuracy else y_pred_nb
best_accuracy = max(lr_accuracy, nb_accuracy)

print(f"\n‚úì Best performing model: {best_model_name} (Accuracy: {best_accuracy:.4f})")


comparison_df.to_csv('/mnt/user-data/outputs/model_comparison.csv', index=False)
print(f"‚úì Saved: model_comparison.csv")


print("\n[STEP 7] GENERATING CONFUSION MATRIX...")
print("-" * 80)

cm = confusion_matrix(y_test, best_predictions)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'],
            annot_kws={'size': 16, 'weight': 'bold'})
plt.title(f'Confusion Matrix - {best_model_name}\nAccuracy: {best_accuracy:.4f}', 
          fontsize=14, fontweight='bold', pad=20)
plt.ylabel('Actual Sentiment', fontsize=12, fontweight='bold')
plt.xlabel('Predicted Sentiment', fontsize=12, fontweight='bold')

# Add text annotations
total = cm.sum()
accuracy_text = f'Total Predictions: {total}\nCorrect: {cm.diagonal().sum()}'
plt.text(1, 2.3, accuracy_text, ha='center', fontsize=10, 
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig('/mnt/user-data/outputs/confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"‚úì Saved: confusion_matrix.png")

# Print detailed classification report
print(f"\nDetailed Classification Report ({best_model_name}):")
print(classification_report(y_test, best_predictions, 
                          target_names=['Negative', 'Positive'],
                          digits=4))

print("\n[STEP 8] ANALYZING FEATURE IMPORTANCE...")
print("-" * 80)


coefficients = lr_model.coef_[0]
feature_importance = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': coefficients
})


top_positive = feature_importance.nlargest(10, 'Coefficient')
top_negative = feature_importance.nsmallest(10, 'Coefficient')

print("\nTop 10 Words Associated with POSITIVE Sentiment:")
for idx, row in top_positive.iterrows():
    print(f"  {row['Feature']:20s}: {row['Coefficient']:.4f}")

print("\nTop 10 Words Associated with NEGATIVE Sentiment:")
for idx, row in top_negative.iterrows():
    print(f"  {row['Feature']:20s}: {row['Coefficient']:.4f}")

# Visualize feature importance
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Positive features
axes[0].barh(range(len(top_positive)), top_positive['Coefficient'].values, 
             color='green', alpha=0.7, edgecolor='black')
axes[0].set_yticks(range(len(top_positive)))
axes[0].set_yticklabels(top_positive['Feature'].values)
axes[0].set_xlabel('Coefficient Value', fontweight='bold')
axes[0].set_title('Top 10 Positive Sentiment Indicators', fontweight='bold', fontsize=12)
axes[0].invert_yaxis()
axes[0].grid(axis='x', alpha=0.3)

# Negative features
axes[1].barh(range(len(top_negative)), top_negative['Coefficient'].values, 
             color='red', alpha=0.7, edgecolor='black')
axes[1].set_yticks(range(len(top_negative)))
axes[1].set_yticklabels(top_negative['Feature'].values)
axes[1].set_xlabel('Coefficient Value', fontweight='bold')
axes[1].set_title('Top 10 Negative Sentiment Indicators', fontweight='bold', fontsize=12)
axes[1].invert_yaxis()
axes[1].grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig('/mnt/user-data/outputs/feature_importance.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\n‚úì Saved: feature_importance.png")

print("\n[STEP 9] CREATING CUSTOM PREDICTION FUNCTION...")
print("-" * 80)

def predict_sentiment(review_text, return_probability=False):
    """
    Predict sentiment for a custom product review
    
    Parameters:
    -----------
    review_text : str
        The review text to analyze
    return_probability : bool
        If True, returns probability scores along with prediction
    
    Returns:
    --------
    dict : Prediction results with sentiment, confidence, and preprocessing info
    """
    # Preprocess the input text
    cleaned_text = preprocess_text(review_text)
    
    # Vectorize using trained TF-IDF
    text_vectorized = tfidf_vectorizer.transform([cleaned_text])
    
    # Make prediction
    prediction = best_model.predict(text_vectorized)[0]
    prediction_proba = best_model.predict_proba(text_vectorized)[0]
    
    # Format results
    sentiment = "Positive" if prediction == 1 else "Negative"
    confidence = prediction_proba[prediction] * 100
    
    result = {
        'original_text': review_text,
        'cleaned_text': cleaned_text,
        'sentiment': sentiment,
        'confidence': confidence,
        'model_used': best_model_name
    }
    
    if return_probability:
        result['probability_negative'] = prediction_proba[0] * 100
        result['probability_positive'] = prediction_proba[1] * 100
    
    return result

print("‚úì Custom prediction function created")

print("\n[STEP 10] TESTING CUSTOM PREDICTION FUNCTION...")
print("-" * 80)

# Test cases
test_reviews = [
    "The product was okay but shipping was slow",
    "Absolutely love this! Best purchase ever!",
    "Terrible quality. Broke after one day. Very disappointed.",
    "Good value for money. Works as expected.",
    "Not worth the price. Very poor quality.",
    "Amazing product! Exceeded all expectations!",
]

print("\nTesting with sample reviews:\n")
predictions_list = []

for i, review in enumerate(test_reviews, 1):
    result = predict_sentiment(review, return_probability=True)
    
    print(f"Test {i}:")
    print(f"  Review: \"{result['original_text']}\"")
    print(f"  Predicted Sentiment: {result['sentiment']}")
    print(f"  Confidence: {result['confidence']:.2f}%")
    print(f"  Probability (Negative): {result['probability_negative']:.2f}%")
    print(f"  Probability (Positive): {result['probability_positive']:.2f}%")
    print()
    
    predictions_list.append({
        'Review': review,
        'Predicted_Sentiment': result['sentiment'],
        'Confidence': f"{result['confidence']:.2f}%"
    })

# Save predictions
predictions_df = pd.DataFrame(predictions_list)
predictions_df.to_csv('/mnt/user-data/outputs/sample_predictions.csv', index=False)
print("‚úì Saved: sample_predictions.csv")

print("\n[STEP 11] CREATING PERFORMANCE VISUALIZATIONS...")
print("-" * 80)


fig, axes = plt.subplots(2, 2, figsize=(14, 10))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
lr_scores = [lr_accuracy, lr_precision, lr_recall, lr_f1]
nb_scores = [nb_accuracy, nb_precision, nb_recall, nb_f1]

x = np.arange(len(metrics))
width = 0.35

axes[0, 0].bar(x - width/2, lr_scores, width, label='Logistic Regression', 
               color='#3498db', alpha=0.8, edgecolor='black')
axes[0, 0].bar(x + width/2, nb_scores, width, label='Naive Bayes', 
               color='#e74c3c', alpha=0.8, edgecolor='black')
axes[0, 0].set_ylabel('Score', fontweight='bold')
axes[0, 0].set_title('Model Performance Comparison', fontweight='bold', fontsize=12)
axes[0, 0].set_xticks(x)
axes[0, 0].set_xticklabels(metrics)
axes[0, 0].legend()
axes[0, 0].set_ylim([0, 1.1])
axes[0, 0].grid(axis='y', alpha=0.3)

# Plot 2: Confusion Matrix (compact)
sns.heatmap(cm, annot=True, fmt='d', cmap='RdYlGn', ax=axes[0, 1], cbar=False,
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])
axes[0, 1].set_title(f'Confusion Matrix - {best_model_name}', fontweight='bold', fontsize=12)
axes[0, 1].set_ylabel('Actual', fontweight='bold')
axes[0, 1].set_xlabel('Predicted', fontweight='bold')

# Plot 3: Class Distribution
class_dist = df['Sentiment'].value_counts()
colors_pie = ['#2ecc71', '#e74c3c']
axes[1, 0].pie(class_dist.values, labels=class_dist.index, autopct='%1.1f%%',
               startangle=90, colors=colors_pie, wedgeprops={'edgecolor': 'black'})
axes[1, 0].set_title('Dataset Class Distribution', fontweight='bold', fontsize=12)

# Plot 4: Word Count Distribution
axes[1, 1].hist([df[df['Sentiment']=='Positive']['Word_Count'], 
                 df[df['Sentiment']=='Negative']['Word_Count']], 
                label=['Positive', 'Negative'], bins=15, alpha=0.7,
                color=['green', 'red'], edgecolor='black')
axes[1, 1].set_xlabel('Word Count', fontweight='bold')
axes[1, 1].set_ylabel('Frequency', fontweight='bold')
axes[1, 1].set_title('Word Count Distribution by Sentiment', fontweight='bold', fontsize=12)
axes[1, 1].legend()
axes[1, 1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('/mnt/user-data/outputs/performance_dashboard.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Saved: performance_dashboard.png")

print("\n" + "="*80)
print("RESUME-READY BULLET POINTS")
print("="*80 + "\n")

resume_text = f"""
‚Ä¢ Engineered an end-to-end NLP sentiment analysis pipeline for product review 
  classification using Python, achieving {best_accuracy*100:.2f}% accuracy on a dataset of 200 
  reviews through TF-IDF vectorization, stopword removal, and {best_model_name} 
  classification with scikit-learn

‚Ä¢ Implemented comprehensive text preprocessing techniques including lowercase conversion, 
  punctuation removal, and stopword filtering, then extracted 500 TF-IDF 
  features with unigram and bigram analysis to train both Logistic Regression 
  ({lr_accuracy*100:.2f}% accuracy) and Naive Bayes ({nb_accuracy*100:.2f}% accuracy) models for binary sentiment classification

‚Ä¢ Built an interactive prediction function enabling real-time sentiment analysis on 
  custom product reviews, with confidence scores and probability distributions, while 
  visualizing model performance through confusion matrices (achieving {cm.diagonal().sum()}/{cm.sum()} 
  correct predictions) and feature importance analysis identifying key sentiment indicators
"""

print(resume_text)

# Save resume bullets
with open('/mnt/user-data/outputs/readme.txt', 'w') as f:
    f.write("PROFESSIONAL RESUME BULLET POINTS\n")
    f.write("NLP Sentiment Analysis Project\n")
    f.write("="*80 + "\n\n")
    f.write(resume_text)
    f.write("\n" + "="*80 + "\n")
    f.write("\nKEY PROJECT METRICS:\n")
    f.write(f"  - Dataset Size: 200 product reviews\n")
    f.write(f"  - Best Model: {best_model_name}\n")
    f.write(f"  - Accuracy: {best_accuracy*100:.2f}%\n")
    f.write(f"  - Precision: {precision_score(y_test, best_predictions)*100:.2f}%\n")
    f.write(f"  - Recall: {recall_score(y_test, best_predictions)*100:.2f}%\n")
    f.write(f"  - F1-Score: {f1_score(y_test, best_predictions):.4f}\n")
    f.write(f"  - TF-IDF Features: {X.shape[1]}\n")
    f.write(f"  - Tools: Python, Scikit-learn, Pandas, Matplotlib, Seaborn, TF-IDF\n")
    f.write("\n" + "="*80 + "\n")
    f.write("\nCUSTOM PREDICTION FUNCTION USAGE:\n")
    f.write("="*80 + "\n")
    f.write("result = predict_sentiment('Your review text here', return_probability=True)\n")
    f.write("print(f\"Sentiment: {result['sentiment']}\")\n")
    f.write("print(f\"Confidence: {result['confidence']:.2f}%\")\n")

print("\n‚úì Saved: resume_bullets.txt")

print("\n" + "="*80)
print("PROJECT COMPLETED SUCCESSFULLY!")
print("="*80)

print("\nüìä PROJECT SUMMARY:")
print(f"  - Total Reviews Analyzed: {len(df)}")
print(f"  - Positive Reviews: {(df['Sentiment']=='Positive').sum()}")
print(f"  - Negative Reviews: {(df['Sentiment']=='Negative').sum()}")
print(f"  - Best Model: {best_model_name}")
print(f"  - Test Accuracy: {best_accuracy*100:.2f}%")
print(f"  - Correctly Classified: {cm.diagonal().sum()}/{cm.sum()} reviews")

print("\nüìÅ GENERATED FILES:")
print("  1. product_reviews_raw.csv - Original synthetic dataset")
print("  2. model_comparison.csv - Performance metrics comparison")
print("  3. sample_predictions.csv - Test predictions on sample reviews")
print("  4. confusion_matrix.png - Model confusion matrix visualization")
print("  5. feature_importance.png - Top positive/negative sentiment words")
print("  6. performance_dashboard.png - Comprehensive performance metrics")
print("  7. resume_bullets.txt - Professional resume bullet points")

print("\nüîß PREDICTION FUNCTION:")
print("  Use predict_sentiment(your_text) to classify any review!")
print("  Example: predict_sentiment('Great product, highly recommend!')")

print("\nüí° KEY INSIGHTS:")
print(f"  - Top positive word: '{top_positive.iloc[0]['Feature']}'")
print(f"  - Top negative word: '{top_negative.iloc[0]['Feature']}'")
print(f"  - Average review length: {df['Word_Count'].mean():.1f} words")
print(f"  - Model generalization: {((best_accuracy - 0.5) / 0.5 * 100):.1f}% above baseline")

print("\n" + "="*80)
print("Ready to showcase your NLP skills on your resume!")
print("="*80)
